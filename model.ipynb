{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict,Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import PeftModel,PeftConfig,get_peft_model,LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like you're importing various modules and classes from the Hugging Face `transformers` library for sequence classification tasks. These imports include:\n",
    "\n",
    "- `AutoTokenizer`: Used to automatically load the appropriate tokenizer for a given pretrained model.\n",
    "- `AutoConfig`: Helps in automatically configuring model settings for a pretrained model.\n",
    "- `AutoModelForSequenceClassification`: Automatically loads a pretrained model for sequence classification.\n",
    "- `DataCollatorWithPadding`: A utility class for collating and handling padding of sequences during training.\n",
    "- `TrainingArguments`: Contains settings and configurations for training a model.\n",
    "- `Trainer`: The training interface provided by the `transformers` library for training models.\n",
    "\n",
    "With these imports, you have access to tools for easily initializing and training sequence classification models using pretrained models provided by Hugging Face's `transformers` library. You can use these components to set up, train, and fine-tune models for various natural language understanding or sequence classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased' #67M base parameter\n",
    "\n",
    "# define label maps\n",
    "id2label = {0:\"Negative\",1:\"Positive\"}\n",
    "label2id = {\"Negative\":0,\"Positive\":1}\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,num_labels = 2,id2label=id2label,label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"shawhin/imdb-truncated\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9417e0ccff44456c93f8c23d6737efad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,add_prefix_space = True)\n",
    "\n",
    "# Create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side=\"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=12\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token':'[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# tokenizer training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataCollatorWithPadding` is a utility class from the Hugging Face `transformers` library used for collating and processing data during training in cases where input sequences have varying lengths. This class specifically handles padding of sequences to ensure uniform lengths within a batch.\n",
    "\n",
    "When working with sequence data for NLP tasks, inputs often have different lengths. However, during training, it's efficient to process inputs in batches, which requires sequences within a batch to have the same length. This is where padding comes inâ€”to ensure uniformity within a batch.\n",
    "\n",
    "`DataCollatorWithPadding` performs the following tasks:\n",
    "- It collates examples into batches.\n",
    "- It pads sequences within each batch to the same length, using a padding token (usually an ID representing padding) to fill in the gaps.\n",
    "\n",
    "Here's an example of how you might use `DataCollatorWithPadding`:\n",
    "\n",
    "```python\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Initialize a DataCollatorWithPadding instance\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create your training arguments and other necessary objects\n",
    "training_args = TrainingArguments(...)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  # Set the data collator for handling padding\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "In this example, `tokenizer` is an instance of the Hugging Face tokenizer that you're using for your model. `DataCollatorWithPadding` is initialized with the tokenizer to handle padding of sequences during training.\n",
    "\n",
    "By using `DataCollatorWithPadding` within the `Trainer`, you ensure that your model processes batches of sequences efficiently by automatically padding them to the same length, allowing for smoother training without having to manually handle padding logic in your training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions,axis=1)\n",
    "\n",
    "    return {\"accuracy\":accuracy.compute(predictions=predictions,\n",
    "                                        references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model prediction\n",
      "--------------------------------------------------\n",
      "It was good - Positive\n",
      "Not a fan,dont recommend - Negative\n",
      "Better than first one - Negative\n",
      "this one is pass - Positive\n"
     ]
    }
   ],
   "source": [
    "### define list of examples\n",
    "text_list = [\"It was good\",\"Not a fan,dont recommend\",\"Better than first one\",\"this one is pass\"]\n",
    "\n",
    "print(\"Untrained model prediction\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "for text in text_list:\n",
    "    # tokenize text\n",
    "    inputs = tokenizer.encode(text,return_tensors=\"pt\")\n",
    "    # Compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # Convert logits to labels\n",
    "    prediction = torch.argmax(logits)\n",
    "\n",
    "    print(text + \" - \" +id2label[prediction.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEFT (Parameterized Entangled Friendly Transformations):\n",
    "PEFT in the context of language models like LLMs involves techniques related to entanglement and transformation of parameters within the model architecture. It's a method that aims to improve the expressiveness and efficiency of language models by introducing entangled transformations that enable more effective parameter interactions within the model. PEFT is a technique that leverages quantum-inspired principles to enhance the learning dynamics or performance of language models.\n",
    "\n",
    "### LoRA (Low Rank Adaptation):\n",
    "LoRA, in the context of language models, specifically refers to \"Low Rank Adaptation,\" which focuses on adapting and compressing the parameters of large language models. This technique aims to reduce the computational overhead and memory requirements of LLMs by leveraging low-rank approximations. By approximating the parameters using low-rank matrices or tensors, LoRA helps in making these models more efficient while preserving their performance to a significant extent.\n",
    "\n",
    "Both PEFT and LoRA are strategies or methodologies used to address challenges related to efficiency, computational requirements, and performance enhancement in large language models like LLMs. While PEFT involves entangled transformations to improve expressiveness, LoRA focuses on low-rank adaptations for parameter compression and efficiency without sacrificing performance significantly.\n",
    "\n",
    "These techniques aim to optimize and improve the capabilities of language models, offering ways to make them more computationally efficient, easier to train, or more scalable for various NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning with LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", # for seuqence classification\n",
    "              r=4, # intrinsic rank of traininable weight matrix,\n",
    "              lora_alpha=32, # this is like a learning rate\n",
    "              lora_dropout=0.01, # probabilty of dropout\n",
    "              target_modules= ['q_lin'],) # we apply lora to query layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9306847223789819\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3 #size of optimization step\n",
    "batch_size = 4 # number of examples processed per optimization step\n",
    "num_epoch = 10 # number of times model runs through training data\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epoch,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1099a44a73274dd5a4db1ec7abb8cae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335eefdbe0ba49e2bbba6cc271776233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.701}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.701}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5780891180038452, 'eval_accuracy': {'accuracy': 0.701}, 'eval_runtime': 2.0084, 'eval_samples_per_second': 497.92, 'eval_steps_per_second': 124.48, 'epoch': 1.0}\n",
      "{'loss': 0.6095, 'learning_rate': 0.0008, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5be77ed714640ea9922b85cf67960e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.692}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.692}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6857352256774902, 'eval_accuracy': {'accuracy': 0.692}, 'eval_runtime': 2.1827, 'eval_samples_per_second': 458.141, 'eval_steps_per_second': 114.535, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d861d0a0430b4e789ea7f8be23572dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.694}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.694}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-750 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.972552478313446, 'eval_accuracy': {'accuracy': 0.694}, 'eval_runtime': 2.0695, 'eval_samples_per_second': 483.198, 'eval_steps_per_second': 120.799, 'epoch': 3.0}\n",
      "{'loss': 0.3927, 'learning_rate': 0.0006, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3eb5b5ff2304861b0754cd7a406268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.704}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.704}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1614502668380737, 'eval_accuracy': {'accuracy': 0.704}, 'eval_runtime': 2.1779, 'eval_samples_per_second': 459.166, 'eval_steps_per_second': 114.791, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157bf506adf34971bc622a34f6309767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.708}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.708}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-1250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3681780099868774, 'eval_accuracy': {'accuracy': 0.708}, 'eval_runtime': 2.1277, 'eval_samples_per_second': 469.988, 'eval_steps_per_second': 117.497, 'epoch': 5.0}\n",
      "{'loss': 0.2128, 'learning_rate': 0.0004, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9022c40de0445e9fb60157d4755610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.705}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.705}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6282109022140503, 'eval_accuracy': {'accuracy': 0.705}, 'eval_runtime': 2.0456, 'eval_samples_per_second': 488.843, 'eval_steps_per_second': 122.211, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a33d7fc8fb4d769b8ea0d4bd2b8599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.697}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.697}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-1750 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7728582620620728, 'eval_accuracy': {'accuracy': 0.697}, 'eval_runtime': 2.0668, 'eval_samples_per_second': 483.85, 'eval_steps_per_second': 120.963, 'epoch': 7.0}\n",
      "{'loss': 0.119, 'learning_rate': 0.0002, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b071607e50164e6da43eeb1704d6860a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.698}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.698}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9462685585021973, 'eval_accuracy': {'accuracy': 0.698}, 'eval_runtime': 2.1016, 'eval_samples_per_second': 475.836, 'eval_steps_per_second': 118.959, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e44ad3983a40fc96e467453cc25087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.697}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.697}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-2250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0068695545196533, 'eval_accuracy': {'accuracy': 0.697}, 'eval_runtime': 2.2825, 'eval_samples_per_second': 438.109, 'eval_steps_per_second': 109.527, 'epoch': 9.0}\n",
      "{'loss': 0.0587, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b88dfcf3946bfa4151ba5f605c4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.702}\" of type <class 'dict'> for key \"eval_accuracy\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.702}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Checkpoint destination directory distilbert-base-uncased-lora-text-classification\\checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.029104232788086, 'eval_accuracy': {'accuracy': 0.702}, 'eval_runtime': 2.2051, 'eval_samples_per_second': 453.488, 'eval_steps_per_second': 113.372, 'epoch': 10.0}\n",
      "{'train_runtime': 79.2352, 'train_samples_per_second': 126.207, 'train_steps_per_second': 31.552, 'train_loss': 0.2785419151306152, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.2785419151306152, metrics={'train_runtime': 79.2352, 'train_samples_per_second': 126.207, 'train_steps_per_second': 31.552, 'train_loss': 0.2785419151306152, 'epoch': 10.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model, # our peft model\n",
    "    args=training_args, # hyperparameter\n",
    "    train_dataset=tokenized_dataset[\"train\"], # training data\n",
    "    eval_dataset=tokenized_dataset[\"validation\"], # validation data\n",
    "    tokenizer=tokenizer, # define tokenizer\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics, # evaluate model using compute_metrics\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n",
      "It was good - Positive\n",
      "Not a fan,dont recommend - Negative\n",
      "Better than first one - Negative\n",
      "this one is pass - Negative\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu') \n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\") \n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
